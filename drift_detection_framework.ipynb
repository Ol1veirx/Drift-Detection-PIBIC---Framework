{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "%pip install yfinance scikit-learn matplotlib pandas ipywidgets tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.SeriesProcessor import SeriesProcessor\n",
    "from classes.frameworkDetector.framework_detector import FrameworkDetector\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import Visualizer\n",
    "from utils.AuxiliaryFunctionFramework import AuxiliaryFunctionFramework\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from classes.detectores.ADWINDetector import ADWINDetector\n",
    "from classes.detectores.DDMDetector import DDMDetector\n",
    "from classes.detectores.EDDMDetector import EDDMDetector\n",
    "from classes.detectores.FHDDMDetector import FHDDMDetector\n",
    "from classes.detectores.HDDM_ADetector import HDDM_ADetector\n",
    "from classes.detectores.PageHinkleyDetector import PageHinkleyDetector\n",
    "from classes.detectores.HDDM_WDetector import HDDM_WDetector\n",
    "from classes.detectores.KSWINDetector import KSWINDetector\n",
    "from classes.modelosOffline.RandomForestModelo import RandomForestModelo # Para retreino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Preparação da Base de Dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Lista de séries temporais disponíveis (para referência)\n",
    "series = [\n",
    "    \"AAPL\",\n",
    "    \"B3SA3.SA\",\n",
    "    \"^IXIC\",\n",
    "    \"^DJI\",\n",
    "    \"^GSPC\",\n",
    "    \"^BVSP\",\n",
    "    \"USDBRL=X\"\n",
    "]\n",
    "\n",
    "# Definindo parâmetros para processamento\n",
    "lags = 5\n",
    "serie_escolhida = series[-2]  # Exemplo: ^BVSP\n",
    "print(f\"Processando série: {serie_escolhida}\")\n",
    "\n",
    "# Baixando os dados\n",
    "serie_temporal = SeriesProcessor.baixar_dados(serie_escolhida)\n",
    "\n",
    "# Normalizando a série temporal\n",
    "serie_temporal_normalizada = SeriesProcessor.normalizar_serie(serie_temporal)\n",
    "print(f\"Shape da série após normalização: {serie_temporal_normalizada.shape}\")\n",
    "\n",
    "# Gerando janelas temporais (features X e target Y)\n",
    "X, Y = SeriesProcessor.criar_janela_temporal(serie_temporal_normalizada, lags)\n",
    "print(f\"Shape dos dados de entrada (X): {X.shape}\")\n",
    "print(f\"Shape dos dados de saída (Y): {Y.shape}\")\n",
    "\n",
    "# Definindo tamanho do conjunto inicial de treinamento (por exemplo, 20% dos dados)\n",
    "initial_size = int(0.2 * len(X))\n",
    "print(f\"Tamanho do conjunto inicial de treinamento: {initial_size} amostras\")\n",
    "\n",
    "# Dividindo os dados em conjunto inicial e streaming\n",
    "X_init = X[:initial_size]\n",
    "y_init = Y[:initial_size]\n",
    "X_stream = X[initial_size:]\n",
    "Y_stream = Y[initial_size:]\n",
    "\n",
    "print(f\"Shape do X_init: {X_init.shape}\")\n",
    "print(f\"Shape do Y_init: {y_init.shape}\")\n",
    "print(f\"Shape do X_stream: {X_stream.shape}\")\n",
    "print(f\"Shape do Y_stream: {Y_stream.shape}\")\n",
    "\n",
    "# Alternativamente, você pode definir um número fixo de amostras iniciais\n",
    "# Por exemplo, 100 primeiras amostras para treinamento\n",
    "fixed_initial_size = 100\n",
    "X_init_fixed = X[:fixed_initial_size]\n",
    "Y_init_fixed = Y[:fixed_initial_size]\n",
    "X_stream_fixed = X[fixed_initial_size:]\n",
    "Y_stream_fixed = Y[fixed_initial_size:]\n",
    "\n",
    "print(\"\\nCom tamanho fixo:\")\n",
    "print(f\"Shape do X_init_fixed: {X_init_fixed.shape}\")\n",
    "print(f\"Shape do Y_init_fixed: {Y_init_fixed.shape}\")\n",
    "print(f\"Shape do X_stream_fixed: {X_stream_fixed.shape}\")\n",
    "print(f\"Shape do Y_stream_fixed: {Y_stream_fixed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Dados Reais de Séries Financeiras\n",
    "def preparar_dados_financeiros(ticker=\"^BVSP\", periodo=\"5y\", lags=10):\n",
    "    \"\"\"Prepara dados de séries financeiras para experimentos\"\"\"\n",
    "    print(f\"Baixando dados para {ticker} nos últimos {periodo}...\")\n",
    "\n",
    "    # Baixar dados\n",
    "    serie_temporal = SeriesProcessor.baixar_dados(ticker, periodo)\n",
    "\n",
    "    # Pré-processamento\n",
    "    serie_normalizada = SeriesProcessor.normalizar_serie(serie_temporal)\n",
    "\n",
    "    # Criar janelas temporais\n",
    "    X, y = SeriesProcessor.criar_janela_temporal(serie_normalizada, lags)\n",
    "\n",
    "    print(f\"Dados processados: {X.shape[0]} amostras com {X.shape[1]} features\")\n",
    "\n",
    "    return X, y, serie_temporal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Inicialização do Framework**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "tamanho_janela = 200\n",
    "intervalo_adicao_pool = 30\n",
    "observacoes_novo_conceito = 75\n",
    "detector_escolhido = \"KSWIN\"\n",
    "tipo_modelo_inicial_global = RandomForestModelo\n",
    "\n",
    "print(\"\\n=== Inicialização do Framework ===\")\n",
    "\n",
    "# 1. Treinar Modelo Inicial e Obter Scaler\n",
    "print(f\"Treinando modelo inicial ({tipo_modelo_inicial_global.__name__}) com {len(X_init)} amostras...\")\n",
    "\n",
    "modelo_inicial, scaler = FrameworkDetector.treinar_modelo_inicial(X_init, y_init, tipo_modelo=tipo_modelo_inicial_global)\n",
    "\n",
    "if modelo_inicial is None:\n",
    "    raise RuntimeError(\"Falha crítica: Não foi possível treinar o modelo inicial.\")\n",
    "\n",
    "# 2. Inicializar Estado do Framework\n",
    "modelo_atual = modelo_inicial\n",
    "pool_modelos = [modelo_inicial]\n",
    "print(f\"\\nModelo inicial ativo: {modelo_atual.nome if hasattr(modelo_atual, 'nome') else type(modelo_atual).__name__}\")\n",
    "print(f\"Pool inicializado com 1 modelo.\")\n",
    "\n",
    "# 3. Inicializar Detector\n",
    "print(f\"Inicializando detector: {detector_escolhido}\")\n",
    "if detector_escolhido == \"DDM\":\n",
    "    detector_wrapper = DDMDetector()\n",
    "elif detector_escolhido == \"ADWIN\":\n",
    "    detector_wrapper = ADWINDetector(delta=0.002)\n",
    "elif detector_escolhido == \"KSWIN\":\n",
    "    detector_wrapper = KSWINDetector(alpha=0.05, window_size=100)\n",
    "elif detector_escolhido == \"HDDM_W\":\n",
    "     detector_wrapper = HDDM_WDetector(drift_confidence=0.001, warning_confidence=0.005)\n",
    "else:\n",
    "    raise ValueError(f\"Detector '{detector_escolhido}' não suportado ou não definido.\")\n",
    "\n",
    "# 4. Inicializar Janela e Contadores/Flags para a nova lógica\n",
    "print(f\"Inicializando janela de dados com as últimas {min(tamanho_janela, len(X_init))} amostras iniciais.\")\n",
    "janela_dados_recentes = list(zip(X_init[-tamanho_janela:], y_init[-tamanho_janela:]))\n",
    "contador_adicao_pool = 0\n",
    "drift_detectado_flag = False\n",
    "contador_novo_conceito = 0\n",
    "buffer_novo_conceito = []\n",
    "\n",
    "# 5. Estruturas para armazenar resultados do stream\n",
    "erros_predicao_stream = []\n",
    "predicoes_stream = []\n",
    "estados_detector_stream = []\n",
    "pontos_drift_detectados = []\n",
    "metricas_rmse_stream = []\n",
    "metricas_mae_stream = []\n",
    "metricas_r2_stream = []\n",
    "modelo_ativo_ao_longo_do_tempo = []\n",
    "tamanho_pool_ao_longo_do_tempo = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Loop Principal de Detecção e Adaptação**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "metrics_interval = 50\n",
    "min_samples_for_metrics = 5\n",
    "max_pool_size = 5\n",
    "\n",
    "print(\"\\n=== Iniciando Processamento do Stream ===\")\n",
    "\n",
    "print(f\"Processando {len(X_stream)} amostras...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i, (x_t, y_t) in enumerate(tqdm(zip(X_stream, Y_stream), total=len(X_stream), desc=\"Stream\")):\n",
    "    indice_global = initial_size + i\n",
    "\n",
    "    # --- 1. Predição ---\n",
    "    x_t_reshaped = x_t.reshape(1, -1)\n",
    "    x_t_scaled = scaler.transform(x_t_reshaped)\n",
    "    y_pred = modelo_atual.prever(x_t_scaled)[0]\n",
    "    predicoes_stream.append(y_pred)\n",
    "\n",
    "    # --- 2. Cálculo do Erro e Atualização do Detector ---\n",
    "    erro = abs(y_t - y_pred)\n",
    "    detector_wrapper.atualizar(erro)\n",
    "    erros_predicao_stream.append(erro)\n",
    "\n",
    "    # --- 3. Obter Estado do Detector ---\n",
    "    estado = FrameworkDetector.get_state(detector_wrapper)\n",
    "    estados_detector_stream.append(estado)\n",
    "\n",
    "    # --- 4. Lógica de Adaptação Baseada no Estado e Flags ---\n",
    "\n",
    "    # --- PASSO 4: Coletando dados para retreino após drift ---\n",
    "    if drift_detectado_flag:\n",
    "        contador_novo_conceito += 1\n",
    "        buffer_novo_conceito.append((x_t, y_t))\n",
    "\n",
    "        if hasattr(modelo_atual, \"partial_fit\"):\n",
    "             modelo_atual.partial_fit(x_t_scaled, np.array([y_t]))\n",
    "\n",
    "        if contador_novo_conceito >= observacoes_novo_conceito:\n",
    "            print(f\"\\n--- Retreinando Modelo ({tipo_modelo_inicial_global.__name__}) após {observacoes_novo_conceito} obs. do novo conceito ---\")\n",
    "            X_novo_list = [x for x, y in buffer_novo_conceito]\n",
    "            y_novo_array = np.array([y for x, y in buffer_novo_conceito])\n",
    "\n",
    "            novo_modelo = FrameworkDetector.treinar_novo_conceito(\n",
    "                np.array(X_novo_list), y_novo_array, scaler, tipo_modelo=tipo_modelo_inicial_global\n",
    "            )\n",
    "\n",
    "            if novo_modelo:\n",
    "                modelo_atual = novo_modelo\n",
    "                pool_modelos = [modelo_atual]\n",
    "                if modelo_a_manter_do_pool_anterior:\n",
    "                    pool_modelos.append(modelo_a_manter_do_pool_anterior)\n",
    "\n",
    "                    if len(pool_modelos) > max_pool_size:\n",
    "                        modelo_removido = pool_modelos.pop(0)\n",
    "\n",
    "                print(f\"  ✓ Modelo atual substituído pelo modelo retreinado. Pool resetado para 1 modelo.\")\n",
    "            else:\n",
    "                print(f\"  ⚠️ Falha ao retreinar. Mantendo modelo atual ('{modelo_atual.nome if hasattr(modelo_atual, 'nome') else type(modelo_atual).__name__}'). Pool não resetado.\")\n",
    "\n",
    "            drift_detectado_flag = False\n",
    "            contador_novo_conceito = 0\n",
    "            buffer_novo_conceito = []\n",
    "            contador_adicao_pool = 0\n",
    "            print(\"--- Retomando operação normal ---\")\n",
    "\n",
    "    # --- Operação Normal / Detecção ---\n",
    "    else:\n",
    "        # --- PASSO 3: Mudança Detectada ---\n",
    "        if estado == \"MUDANÇA\":\n",
    "            pontos_drift_detectados.append(indice_global)\n",
    "            print(f\"\\n!!! Drift detectado no índice global {indice_global} (Detector: {detector_escolhido}) !!!\")\n",
    "            print(\"  Iniciando avaliação do pool...\")\n",
    "\n",
    "            melhor_do_pool = FrameworkDetector.selecionar_melhor_modelo(pool_modelos, janela_dados_recentes, scaler)\n",
    "            modelo_a_manter_do_pool_anterior = None\n",
    "\n",
    "            if melhor_do_pool:\n",
    "                print(f\"  ✓ Substituindo modelo atual pelo melhor do pool: '{melhor_do_pool.nome if hasattr(melhor_do_pool, 'nome') else type(melhor_do_pool).__name__}'\")\n",
    "                modelo_atual = melhor_do_pool\n",
    "                modelo_a_manter_do_pool_anterior = copy.deepcopy(melhor_do_pool)\n",
    "            else:\n",
    "                print(\"  ⚠️ Não foi possível selecionar um modelo melhor do pool. Mantendo modelo atual.\")\n",
    "                modelo_a_manter_do_pool = copy.deepcopy(modelo_atual)\n",
    "\n",
    "            drift_detectado_flag = True\n",
    "            contador_novo_conceito = 0\n",
    "            buffer_novo_conceito = [(x_t, y_t)]\n",
    "            print(f\"  Iniciando coleta de dados para retreino ({observacoes_novo_conceito} amostras necessárias).\")\n",
    "\n",
    "        # --- PASSO 2: Alerta Detectado ---\n",
    "        elif estado == \"ALERTA\":\n",
    "            if hasattr(modelo_atual, \"partial_fit\"):\n",
    "                modelo_atual.partial_fit(x_t_scaled, np.array([y_t]))\n",
    "\n",
    "        # --- PASSO 1: Estado Normal - Adição Periódica ao Pool ---\n",
    "        elif estado == \"NORMAL\":\n",
    "            contador_adicao_pool += 1\n",
    "            if contador_adicao_pool >= intervalo_adicao_pool:\n",
    "                print(f\"\\n  Adicionando cópia de '{modelo_atual.nome if hasattr(modelo_atual, 'nome') else type(modelo_atual).__name__}' ao pool (a cada {intervalo_adicao_pool} obs).\")\n",
    "                pool_modelos.append(copy.deepcopy(modelo_atual))\n",
    "\n",
    "                if len(pool_modelos) > max_pool_size:\n",
    "                    modelo_removido = pool_modelos.pop(0)\n",
    "\n",
    "                contador_adicao_pool = 0\n",
    "                print(f\"  Tamanho do pool agora: {len(pool_modelos)}\")\n",
    "\n",
    "\n",
    "    # --- 5. Armazenar Resultados da Iteração ---\n",
    "    modelo_ativo_ao_longo_do_tempo.append(modelo_atual.nome if hasattr(modelo_atual, 'nome') else type(modelo_atual).__name__)\n",
    "    tamanho_pool_ao_longo_do_tempo.append(len(pool_modelos))\n",
    "\n",
    "    # --- 6. Calcular Métricas Periodicamente ---\n",
    "    if i > 0 and i % metrics_interval == 0 and len(janela_dados_recentes) >= min_samples_for_metrics:\n",
    "        X_janela_eval = np.array([x for x, _ in janela_dados_recentes])\n",
    "        y_janela_eval = np.array([y for _, y in janela_dados_recentes])\n",
    "        X_janela_eval_scaled = scaler.transform(X_janela_eval)\n",
    "        y_prev_eval = modelo_atual.prever(X_janela_eval_scaled)\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_janela_eval, y_prev_eval))\n",
    "        mae = mean_absolute_error(y_janela_eval, y_prev_eval)\n",
    "        r2 = r2_score(y_janela_eval, y_prev_eval)\n",
    "\n",
    "        metricas_rmse_stream.append((indice_global, rmse))\n",
    "        metricas_mae_stream.append((indice_global, mae))\n",
    "        metricas_r2_stream.append((indice_global, r2))\n",
    "\n",
    "    # --- 7. Atualizar Janela de Dados Recentes ---\n",
    "    janela_dados_recentes = FrameworkDetector.adicionar_a_janela(\n",
    "        janela_dados_recentes,\n",
    "        (x_t, y_t),\n",
    "        tamanho_max=tamanho_janela\n",
    "    )\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\n=== Processamento do Stream Concluído ===\")\n",
    "print(f\"Tempo total: {end_time - start_time:.2f} segundos\")\n",
    "print(f\"Drifts detectados: {len(pontos_drift_detectados)}\")\n",
    "if pontos_drift_detectados:\n",
    "    print(f\"  Nos índices: {pontos_drift_detectados}\")\n",
    "print(f\"Tamanho final do pool: {len(pool_modelos)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Análise e Visualização dos Resultados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "Visualizer.analisar_e_visualizar_resultados_stream(\n",
    "    initial_size=initial_size,\n",
    "    erros_predicao_stream=erros_predicao_stream,\n",
    "    estados_detector_stream=estados_detector_stream,\n",
    "    pontos_drift_detectados=pontos_drift_detectados,\n",
    "    metricas_rmse_stream=metricas_rmse_stream,\n",
    "    metricas_mae_stream=metricas_mae_stream,\n",
    "    metricas_r2_stream=metricas_r2_stream,\n",
    "    modelo_ativo_ao_longo_do_tempo=modelo_ativo_ao_longo_do_tempo,\n",
    "    tamanho_pool_ao_longo_do_tempo=tamanho_pool_ao_longo_do_tempo,\n",
    "    detector_escolhido=detector_escolhido,\n",
    "    serie_escolhida=serie_escolhida\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "Visualizer.visualizar_previsoes_vs_real(\n",
    "    initial_size=initial_size,\n",
    "    Y_stream=Y_stream,\n",
    "    predicoes_stream=predicoes_stream,\n",
    "    pontos_drift_detectados=pontos_drift_detectados,\n",
    "    serie_escolhida=serie_escolhida\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
